import { fs, path } from 'zx';
import crypto from 'crypto';
import { EpistemicLedger } from './EpistemicLedger.js';

// Numerical stability threshold for EQBSL tensor normalization
const MIN_NORMALIZATION_SUM = 1e-10;

/**
 * WorldModel - The central source of truth for the agent's knowledge.
 * 
 * Stores:
 * - Evidence: Raw facts observed (scan results, http responses)
 * - Claims: Assertions made by agents based on evidence
 * - Artifacts: Files/Objects generated by agents
 * 
 * Features:
 * - EQBSL tensor storage on all evidence and claims
 * - Deterministic serialization (canonical sorting)
 * - Export formats (JSON, JSONL)
 * - Provenance tracking
 * 
 * EQBSL Integration:
 * Each claim and evidence item carries an EQBSL tensor (b, d, u, a):
 * - b (belief): Confidence the claim is true
 * - d (disbelief): Confidence the claim is false  
 * - u (uncertainty): Lack of evidence either way
 * - a (base rate): Prior probability
 * Constraint: b + d + u = 1
 */
/**
 * Common event types for evidence classification
 * (Unified from v2/worldmodel/evidence-graph.js)
 */
export const EVENT_TYPES = {
    // Network recon
    HTTP_RESPONSE: 'http_response',
    PORT_SCAN: 'port_scan',
    DNS_RECORD: 'dns_record',
    TLS_CERT: 'tls_cert',
    SUBDOMAIN: 'subdomain',

    // Crawling
    ENDPOINT_DISCOVERED: 'endpoint_discovered',
    FORM_DISCOVERED: 'form_discovered',
    LINK_DISCOVERED: 'link_discovered',

    // JS Analysis
    JS_FETCH_CALL: 'js_fetch_call',
    JS_ROUTE_STRING: 'js_route_string',
    JS_STATE_HINT: 'js_state_hint',

    // Schema
    OPENAPI_FRAGMENT: 'openapi_fragment',
    GRAPHQL_SCHEMA: 'graphql_schema',

    // Validation
    VALIDATION_RESULT: 'validation_result',

    // Tool status
    TOOL_ERROR: 'tool_error',
    TOOL_TIMEOUT: 'tool_timeout',
};

export class WorldModel {
    /**
     * @param {string} workspaceDir - Directory for workspace files
     * @param {Object} options - Configuration options
     * @param {number} options.defaultBaseRate - EQBSL base rate (default 0.5)
     * @param {number} options.priorWeight - K parameter for evidence weighting (default 2.0)
     */
    constructor(workspaceDir, options = {}) {
        this.workspaceDir = workspaceDir;
        this.evidence = new Map(); // id -> Evidence
        this.claims = new Map();   // id -> Claim
        this.artifacts = new Map(); // id -> Artifact
        this.relations = []; // { source, target, type }

        // Evidence indices (unified from v2/worldmodel/evidence-graph.js)
        this.evidenceByAgent = new Map();  // agentName -> Set<id>
        this.evidenceByType = new Map();   // toolType -> Set<id>
        this.evidenceByTarget = new Map(); // targetId -> Set<id>

        // EQBSL configuration
        this.priorWeight = options.priorWeight || 2.0;  // K parameter
        this.defaultBaseRate = options.defaultBaseRate || 0.5;

        // Create EpistemicLedger for tracking opinions
        this.ledger = new EpistemicLedger(this.defaultBaseRate);
    }

    /**
     * Initialize the workspace
     */
    async init() {
        if (this.workspaceDir) {
            await fs.ensureDir(this.workspaceDir);
        }
    }

    /**
     * Derive EQBSL tensor from confidence and evidence count.
     * 
     * Uses the EBSL evidence-to-opinion mapping:
     *   b = r / (r + s + K)
     *   d = s / (r + s + K)
     *   u = K / (r + s + K)
     * 
     * Where:
     *   r = positive evidence (derived from confidence × evidence count)
     *   s = negative evidence (derived from (1-confidence) × evidence count)
     *   K = prior weight (this.priorWeight)
     * 
     * @param {number} confidence - Confidence score 0-1
     * @param {number} evidenceCount - Number of supporting evidence items
     * @returns {Object} EQBSL tensor {b, d, u, a}
     * @private
     */
    _deriveEqbsl(confidence, evidenceCount) {
        const K = this.priorWeight;

        // Map confidence and evidence count to r/s values
        // More evidence = lower uncertainty
        // Higher confidence = more belief relative to disbelief
        const totalEvidence = Math.max(evidenceCount, 0.1); // Avoid divide by zero
        const r = confidence * totalEvidence;
        const s = (1 - confidence) * totalEvidence * 0.3; // Dampen negative evidence

        const denom = r + s + K;
        const b = r / denom;
        const d = s / denom;
        const u = K / denom;

        // Normalize to ensure b + d + u = 1 (handle floating point)
        const sum = b + d + u;
        
        // Prevent division by zero or numerical instability
        if (sum < MIN_NORMALIZATION_SUM) {
            // Fallback to maximum uncertainty if normalization fails
            return {
                b: 0,
                d: 0,
                u: 1,
                a: this.defaultBaseRate
            };
        }

        return {
            b: b / sum,
            d: d / sum,
            u: u / sum,
            a: this.defaultBaseRate
        };
    }

    /**
     * Derive EQBSL tensor for raw evidence.
     * 
     * Evidence has high uncertainty since it's raw observation,
     * but moderate belief since the tool output exists.
     * 
     * @param {string} toolType - Type of tool that produced evidence
     * @returns {Object} EQBSL tensor {b, d, u, a}
     * @private
     */
    _deriveEvidenceEqbsl(toolType) {
        // Tool outputs are generally trustworthy but represent single observations
        // High uncertainty because we don't yet know what the evidence means
        const toolReliability = {
            'nmap': { b: 0.7, d: 0.05, u: 0.25 },      // Network scans are reliable
            'subfinder': { b: 0.65, d: 0.05, u: 0.30 }, // Subdomain enum fairly reliable
            'whatweb': { b: 0.6, d: 0.1, u: 0.30 },    // Tech detection has false positives
            'endpoint': { b: 0.5, d: 0.1, u: 0.40 },   // Endpoints may be stale
            'javascript': { b: 0.4, d: 0.1, u: 0.50 }, // JS analysis is heuristic
            'default': { b: 0.3, d: 0.1, u: 0.60 }     // Unknown tools
        };

        const base = toolReliability[toolType] || toolReliability['default'];
        return { ...base, a: this.defaultBaseRate };
    }

    /**
     * Add a piece of raw evidence
     * @param {Object} data - The evidence data
     * @param {string} sourceAgent - Agent producing the evidence
     * @param {Object} [eqbslOverride] - Optional explicit EQBSL tensor
     * @returns {string} Evidence ID
     */
    addEvidence(data, sourceAgent, eqbslOverride = null) {
        const id = this._generateId(data);

        // Derive EQBSL from tool type or use override
        const toolType = data.tool || data.type || 'default';
        const eqbsl = eqbslOverride || this._deriveEvidenceEqbsl(toolType);

        const evidence = {
            id,
            type: 'evidence',
            content: data,
            sourceAgent,
            eqbsl,  // EQBSL tensor stored on evidence
            timestamp: new Date().toISOString()
        };

        this.evidence.set(id, evidence);

        // Index by agent (unified from v2 EvidenceGraph)
        if (!this.evidenceByAgent.has(sourceAgent)) {
            this.evidenceByAgent.set(sourceAgent, new Set());
        }
        this.evidenceByAgent.get(sourceAgent).add(id);

        // Index by type
        if (!this.evidenceByType.has(toolType)) {
            this.evidenceByType.set(toolType, new Set());
        }
        this.evidenceByType.get(toolType).add(id);

        // Index by target if present
        const target = data.target || data.path || null;
        if (target) {
            if (!this.evidenceByTarget.has(target)) {
                this.evidenceByTarget.set(target, new Set());
            }
            this.evidenceByTarget.get(target).add(id);
        }

        // Register in epistemic ledger
        this.ledger.registerOpinion(id, eqbsl.b, eqbsl.d, eqbsl.u, eqbsl.a);

        return id;
    }

    /**
     * Get all evidence from a specific agent
     * @param {string} agentName - Agent name
     * @returns {Object[]} Array of evidence objects
     */
    getEvidenceByAgent(agentName) {
        const ids = this.evidenceByAgent.get(agentName) || new Set();
        return Array.from(ids).map(id => this.evidence.get(id));
    }

    /**
     * Get all evidence of a specific type
     * @param {string} toolType - Tool/evidence type
     * @returns {Object[]} Array of evidence objects
     */
    getEvidenceByType(toolType) {
        const ids = this.evidenceByType.get(toolType) || new Set();
        return Array.from(ids).map(id => this.evidence.get(id));
    }

    /**
     * Get all evidence for a specific target
     * @param {string} target - Target identifier
     * @returns {Object[]} Array of evidence objects
     */
    getEvidenceByTarget(target) {
        const ids = this.evidenceByTarget.get(target) || new Set();
        return Array.from(ids).map(id => this.evidence.get(id));
    }

    /**
     * Add a claim derived from evidence
     * @param {string} subject - What the claim is about
     * @param {string} predicate - The attribute/relation
     * @param {any} object - The value
     * @param {number} confidence - 0.0 to 1.0
     * @param {string[]} evidenceIds - IDs of supporting evidence
     * @param {Object} [eqbslOverride] - Optional explicit EQBSL tensor
     * @returns {string} Claim ID
     */
    addClaim(subject, predicate, object, confidence, evidenceIds = [], eqbslOverride = null) {
        const claimData = { subject, predicate, object };
        const id = this._generateId(claimData);

        // Derive EQBSL from confidence and evidence count, or use override
        const eqbsl = eqbslOverride || this._deriveEqbsl(confidence, evidenceIds.length);

        const claim = {
            id,
            type: 'claim',
            subject,
            predicate,
            object,
            confidence,
            eqbsl,  // EQBSL tensor stored on claim
            evidenceIds,
            timestamp: new Date().toISOString()
        };

        this.claims.set(id, claim);

        // Register in epistemic ledger
        this.ledger.registerOpinion(id, eqbsl.b, eqbsl.d, eqbsl.u, eqbsl.a);

        // Link evidence to claim
        evidenceIds.forEach(eid => {
            this.relations.push({ source: eid, target: id, type: 'supports' });
        });

        return id;
    }

    /**
     * Get the expectation (probability estimate) for a claim or evidence
     * @param {string} id - Claim or evidence ID
     * @returns {number} E = b + a*u
     */
    getExpectation(id) {
        return this.ledger.getExpectation(id);
    }

    /**
     * Get the uncertainty for a claim or evidence
     * @param {string} id - Claim or evidence ID
     * @returns {number} Uncertainty 0-1
     */
    getUncertainty(id) {
        return this.ledger.getUncertainty(id);
    }

    /**
     * Get claims with highest uncertainty (need more evidence)
     * @param {number} limit - Max results
     * @returns {Array} Claims sorted by uncertainty
     */
    getHighUncertaintyClaims(limit = 10) {
        return this.ledger.getTopUncertainty(limit)
            .filter(op => this.claims.has(op.id))
            .map(op => ({ ...this.claims.get(op.id), ...op }));
    }

    /**
     * Get controversial claims (significant belief AND disbelief)
     * @param {number} limit - Max results
     * @returns {Array} Claims sorted by controversy
     */
    getControversialClaims(limit = 10) {
        return this.ledger.getTopControversial(limit)
            .filter(op => this.claims.has(op.id))
            .map(op => ({ ...this.claims.get(op.id), ...op }));
    }

    /**
     * Register an artifact
     * @param {string} filePath - Path relative to workspace
     * @param {string} type - Artifact type (report, code, etc)
     * @returns {string} Artifact ID
     */
    addArtifact(filePath, type, metadata = {}) {
        const id = this._generateId({ filePath, type });
        const artifact = {
            id,
            type: 'artifact',
            path: filePath,
            artifactType: type,
            metadata,
            timestamp: new Date().toISOString()
        };
        this.artifacts.set(id, artifact);
        return id;
    }

    /**
     * Export the entire graph to a JSON object
     * @returns {Object}
     */
    toJSON() {
        return {
            meta: {
                version: '1.1.0',
                priorWeight: this.priorWeight,
                defaultBaseRate: this.defaultBaseRate,
                exportedAt: new Date().toISOString()
            },
            evidence: Array.from(this.evidence.values()).sort(this._canonicalSort),
            claims: Array.from(this.claims.values()).sort(this._canonicalSort),
            artifacts: Array.from(this.artifacts.values()).sort(this._canonicalSort),
            relations: this.relations.sort((a, b) =>
                (a.source + a.target).localeCompare(b.source + b.target)
            )
        };
    }

    /**
     * Export to JSON file
     * @param {string} [filename='world-model.json'] 
     */
    async export(filename = 'world-model.json') {
        if (!this.workspaceDir) throw new Error("No workspace directory set");

        const filePath = path.join(this.workspaceDir, filename);
        const data = JSON.stringify(this.toJSON(), null, 2);
        await fs.writeFile(filePath, data);
        return filePath;
    }

    /**
     * Generate a deterministic ID based on content
     * @private
     */
    _generateId(content) {
        const canonical = JSON.stringify(content, Object.keys(content).sort());
        return crypto.createHash('sha256').update(canonical).digest('hex').substring(0, 16);
    }

    /**
     * Sort function for deterministic output
     * @private
     */
    _canonicalSort(a, b) {
        return a.id.localeCompare(b.id);
    }
}
